# Pruebas de Rendimiento y Estr√©s con Locust

##  Descripci√≥n

Este directorio contiene las pruebas de rendimiento y estr√©s para el sistema e-commerce usando **Locust**.

Las pruebas simulan casos de uso reales con diferentes niveles de carga para validar:
- **Rendimiento**: Tiempo de respuesta bajo carga normal
- **Estr√©s**: Comportamiento bajo carga extrema
- **Escalabilidad**: Capacidad de manejar m√∫ltiples usuarios simult√°neos

##  Estructura

```
performance-tests/
‚îú‚îÄ‚îÄ locustfile.py         # Script principal de Locust con escenarios
‚îú‚îÄ‚îÄ requirements.txt      # Dependencias Python
‚îî‚îÄ‚îÄ README.md            # Este archivo
```

##  Escenarios Implementados

### Product Service (Peso 20)
- **Listar productos** (10x): Operaci√≥n m√°s frecuente
- **Obtener producto por ID** (5x): Consulta individual
- **Listar categor√≠as** (3x): Consulta de categor√≠as
- **Crear producto** (2x): Operaci√≥n de escritura

### User Service (Peso 11)
- **Listar usuarios** (8x): Consulta frecuente
- **Crear usuario** (3x): Operaci√≥n de escritura

### Order Service (Peso 8)
- **Listar √≥rdenes** (6x): Consulta frecuente
- **Crear orden completa** (2x): Flujo complejo (user ‚Üí cart ‚Üí order)

---

##  C√≥mo Ejecutar Localmente

### Prerrequisitos

#### 1. Verificar Python instalado

```powershell
# En PowerShell (Windows)
python --version
# Debe mostrar: Python 3.x.x

# Si no est√° instalado, descarga desde: https://www.python.org/downloads/
```

#### 2. Instalar Locust

```powershell
# Navegar a la carpeta de performance tests
cd ecommerce-api-gateway/performance-tests

# Instalar dependencias
pip install -r requirements.txt

# O si pip no est√° en PATH:
python -m pip install -r requirements.txt

# Verificar instalaci√≥n
python -m locust --version
```

---

##  Modos de Ejecuci√≥n

### Modo 1: Con Interfaz Web (Recomendado para pruebas)

#### Pasos:

1. **Navegar a la carpeta**:
   ```powershell
   cd ecommerce-api-gateway/performance-tests
   ```

2. **Ejecutar Locust con UI**:
   ```powershell
   # Opci√≥n 1: Si locust est√° en PATH
   locust -f locustfile.py --host=http://20.15.17.8:8080
   
   # Opci√≥n 2: Si locust NO est√° en PATH (recomendado para Windows)
   python -m locust -f locustfile.py --host=http://20.15.17.8:8080
   ```

3. **Abrir en el navegador**:
   - URL: http://localhost:8089
   - Te mostrar√° una interfaz web donde puedes configurar:
     - **Number of users**: 10-50 (empieza con 10)
     - **Spawn rate**: 2 (usuarios por segundo)
     - **Host**: Ya est√° configurado (http://20.15.17.8:8080)

4. **Hacer clic en "Start swarming"**

5. **Ver resultados en tiempo real**:
   - Estad√≠sticas por endpoint
   - Gr√°ficos de response time
   - N√∫mero de requests por segundo
   - Errores si los hay

6. **Detener el test**:
   - **Con tiempo l√≠mite**: El test terminar√° autom√°ticamente si configuraste `--run-time`
   - **Sin tiempo l√≠mite**: El test correr√° **indefinidamente** hasta que:
     - Hagas clic en el bot√≥n **"STOP"** (rojo) en la interfaz web
     - O presiones **Ctrl+C** en la terminal

7. **Cu√°ndo detener**:
   - **M√≠nimo recomendado**: Deja correr al menos 2-5 minutos para tener datos significativos
   - **Ideal**: 5-10 minutos para obtener m√©tricas estables
   - **Observar**: Revisa las m√©tricas en tiempo real y det√©n cuando:
     - Veas que las m√©tricas se estabilizan (RPS constante, response time estable)
     - O cuando hayas alcanzado el n√∫mero de requests que necesitas probar

---

### Modo 2: Headless (Sin UI, con par√°metros)

Ejecutar directamente con par√°metros desde la l√≠nea de comandos:

```powershell
cd ecommerce-api-gateway/performance-tests

# Usar python -m locust si locust no est√° en PATH
python -m locust -f locustfile.py `
  --host=http://20.15.17.8:8080 `
  --users=10 `
  --spawn-rate=2 `
  --run-time=2m `
  --headless `
  --html=locust-report.html `
  --csv=locust-results
```

**Par√°metros**:
- `--users=10`: 10 usuarios concurrentes (empieza con pocos)
- `--spawn-rate=2`: 2 usuarios por segundo (ritmo de inicio)
- `--run-time=2m`: Duraci√≥n de 2 minutos
- `--headless`: Sin interfaz web
- `--html=locust-report.html`: Genera reporte HTML
- `--csv=locust-results`: Genera CSV con datos

**Ver resultados**:

Despu√©s de ejecutar, tendr√°s:
- `locust-report.html` ‚Üí Abre en el navegador para ver gr√°ficos
- `locust-results_stats.csv` ‚Üí Datos estad√≠sticos
- `locust-results_failures.csv` ‚Üí Errores si los hay

---

##  Ejemplos de Configuraci√≥n de Carga

### Carga Ligera (Prueba inicial)
```powershell
python -m locust -f locustfile.py --host=http://20.15.17.8:8080 --users=5 --spawn-rate=1 --run-time=1m --headless
```

### Carga Media (Stage simulation)
```powershell
python -m locust -f locustfile.py --host=http://20.15.17.8:8080 --users=50 --spawn-rate=5 --run-time=5m --headless --html=report.html
```

### Carga Extrema (Stress test)
```powershell
python -m locust -f locustfile.py --host=http://20.15.17.8:8080 --users=100 --spawn-rate=10 --run-time=10m --headless --html=stress-report.html
```

### Par√°metros Recomendados por Ambiente

| Ambiente | Usuarios | Spawn Rate | Duraci√≥n |
|----------|----------|------------|----------|
| Desarrollo | 10-20 | 2 usuarios/seg | 2 minutos |
| Stage | 50-100 | 5 usuarios/seg | 5 minutos |
| Estr√©s | 200-500 | 10 usuarios/seg | 10 minutos |

---

## üìà C√≥mo Leer los Resultados

### Estado del Test

**Cuando est√° Corriendo**:
- **Status**: RUNNING (en verde)
- **Users**: N√∫mero de usuarios concurrentes simulados
- **RPS**: Requests por segundo
- **Failures**: Porcentaje de errores (idealmente 0%)

**Cu√°ndo Detener el Test**:

- **Modo Manual (UI)**: El test corre **indefinidamente** hasta que hagas clic en **"STOP"** o presiones **Ctrl+C**
- **Con Tiempo L√≠mite**: Ejecuta con `--run-time` y terminar√° autom√°ticamente

**Tiempo Recomendado**:
- **M√≠nimo**: 2-3 minutos (para datos b√°sicos)
- **Recomendado**: 5-10 minutos (para m√©tricas estables)
- **Extendido**: 10-30 minutos (para pruebas de resistencia)

---

### M√©tricas Importantes

#### En la Tabla de Estad√≠sticas:

1. **Response Times (ms)**
   - **Median (p50)**: Tiempo mediano - el 50% de requests son m√°s r√°pidos
   - **95%ile (p95)**: El 95% de requests son m√°s r√°pidos - **m√©trica clave**
   - **99%ile (p99)**: El 99% de requests son m√°s r√°pidos
   - **Average**: Promedio
   - **Min/Max**: Tiempos m√≠nimo y m√°ximo

2. **# Requests**
   - Total de requests ejecutados por endpoint

3. **# Fails**
   - N√∫mero de requests que fallaron
   - **Ideal**: 0

4. **Current RPS**
   - Requests por segundo en ese momento
   - Debe mantenerse estable

5. **Current Failures/s**
   - Errores por segundo
   - **Ideal**: 0

### Criterios de √âxito

 **GET Requests (Lecturas)**:
- p95 < 500ms
- p99 < 1000ms
- Failure rate = 0%

 **POST Requests (Escrituras)**:
- p95 < 1000ms
- p99 < 2000ms
- Failure rate = 0%

 **Sistema Estable**:
- RPS constante (no decreciendo)
- Response times estables (no incrementando)
- Sin errores

---

### Qu√© Observar en Tiempo Real

1. **Estabilizaci√≥n de M√©tricas**
   - Durante los primeros 30-60 segundos, las m√©tricas pueden variar
   - Despu√©s deber√≠an estabilizarse
   - **Espera** hasta ver m√©tricas constantes antes de detener

2. **Tasa de Errores**
   - Si ves errores (> 0% failures), det√©n el test
   - Revisa los logs en la pesta√±a "Failures"
   - **Acci√≥n**: Investigar qu√© endpoints fallan y por qu√©

3. **Degradaci√≥n de Performance**
   - Si los response times aumentan con el tiempo ‚Üí problema
   - Si RPS decrece ‚Üí el sistema est√° sobrecargado
   - **Acci√≥n**: Detener el test y revisar recursos (CPU, memoria)

4. **RPS Consistente**
   - El RPS debe mantenerse estable
   - Si baja mucho ‚Üí el sistema no puede manejar la carga
   - **Acci√≥n**: Reducir n√∫mero de usuarios o revisar configuraci√≥n

---

### Qu√© Hacer Despu√©s del Test

1. **Revisar Tabla de Estad√≠sticas**
   - Identifica endpoints con mayor tiempo de respuesta
   - Revisa si alg√∫n endpoint tiene errores
   - Anota los p95 y p99 para documentaci√≥n

2. **Descargar Reportes** (si ejecutaste con `--html` y `--csv`)
   - **HTML Report**: Gr√°ficos visuales y estad√≠sticas detalladas
   - **CSV Files**: Datos para an√°lisis en Excel o herramientas de BI

3. **Revisar Gr√°ficos**
   - En la pesta√±a "Charts" ver√°s:
     - Response times a lo largo del tiempo
     - RPS a lo largo del tiempo
     - N√∫mero de usuarios

4. **Interpretar Resultados**
   - **Todo en verde (0% failures)**:  Sistema funciona bien
   - **Response times bajos**:  Sistema responde r√°pido
   - **RPS alto y estable**:  Sistema maneja la carga bien
   - **Errores o timeouts**:  Investigar qu√© falla

---

###  Se√±ales de Alerta (Detener Inmediatamente)

Si ves alguno de estos, **det√©n el test**:

1. **Failure rate > 5%**: Demasiados errores
2. **Response times > 5000ms** constantemente: Sistema muy lento
3. **RPS cayendo constantemente**: Sistema sobrecargado
4. **Errores de conexi√≥n**: Problema de red o servicios ca√≠dos

---

###  Ejemplo de Resultados Exitosos

```
Status: RUNNING ‚Üí Status: STOPPED
Users: 10
Total Requests: 1500
Failures: 0 (0%)
Median Response Time: 88ms
95%ile Response Time: 234ms
Average Response Time: 110ms
RPS: 5 (estable)
```

**Interpretaci√≥n**:  Sistema funciona perfectamente bajo esta carga

---

##  Debugging

### Error: "pip no se reconoce"
```powershell
# Usar python -m pip en su lugar
python -m pip install -r requirements.txt
```

### Error: "locust no se reconoce" (Com√∫n en Windows)
```powershell
# Siempre usar python -m locust en lugar de solo locust:
python -m locust -f locustfile.py --host=http://20.15.17.8:8080
```

### Error: "Connection refused"
- Verificar que el API Gateway est√° accesible:
  ```powershell
  curl http://20.15.17.8:8080/actuator/health
  ```

### Error: "No module named 'locust'"
```powershell
# Reinstalar
pip install locust>=2.20.0
```

### Verificar servicios mientras corre Locust:
```powershell
# Ver logs en tiempo real
kubectl logs -n ecommerce-dev deployment/product-service --tail=50 -f

# Ver uso de recursos
kubectl top pods -n ecommerce-dev

# Ver detalles de un pod
kubectl describe pod -n ecommerce-dev -l app=product-service
```

---

##  Ejecutar desde Pipeline CI/CD

El pipeline de Stage ejecutar√° autom√°ticamente las pruebas despu√©s del deploy:

```yaml
- name: Run Performance Tests
  run: |
    cd api-gateway/performance-tests
    pip install -r requirements.txt
    locust -f locustfile.py \
      --host=http://20.15.17.8:8080 \
      --users=50 \
      --spawn-rate=5 \
      --run-time=5m \
      --headless \
      --html=locust-report.html \
      --csv=locust-results
```

Los pipelines de `product-service`, `user-service`, y `order-service` incluyen este job cuando se ejecutan en la rama `stage`.

---

##  Notas Importantes

- **Datos de Prueba**: Las pruebas crean datos reales (productos, usuarios, √≥rdenes)
- **SKU √önicos**: Se generan SKUs √∫nicos con timestamps para evitar duplicados
- **Cleanup**: No hay cleanup autom√°tico (aceptable para Stage)
- **Host Configurable**: El host se puede cambiar v√≠a par√°metro `--host`
- **Primera vez**: Empieza con carga ligera (5-10 usuarios, 1 minuto)
- **Pruebas incrementales**: Aumenta usuarios gradualmente (10 ‚Üí 25 ‚Üí 50)

---

##  Consejos

1. **Primera prueba**: Empieza con pocos usuarios (5-10) y tiempo corto (2 min)
2. **Pruebas incrementales**: Aumenta usuarios gradualmente (10 ‚Üí 25 ‚Üí 50)
3. **Monitoreo paralelo**: Mientras corre Locust, revisa logs de Kubernetes
4. **Recursos**: Verifica uso de CPU/memoria en Kubernetes durante las pruebas

---

##  Pr√≥ximos Pasos

1.  Locustfile con escenarios b√°sicos
2.  Integrar en pipeline de Stage
3.  Configurar reportes HTML/CSV
4.  Agregar m√©tricas avanzadas (percentiles, gr√°ficos)

---
